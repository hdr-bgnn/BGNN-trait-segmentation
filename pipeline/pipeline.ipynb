{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the trained model from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1HBSGXbWw5Vorj82buF-gCi6S2DpF4mFL\n",
      "To: /home/maruf/pipeline/saved_models/Trained_model_SM.pth\n",
      "100%|█████████████████████████████████████████| 113M/113M [00:01<00:00, 104MB/s]\n"
     ]
    }
   ],
   "source": [
    "! gdown -O saved_models/ https://drive.google.com/uc?id=1HBSGXbWw5Vorj82buF-gCi6S2DpF4mFL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as albu\n",
    "\n",
    "import seaborn as sns\n",
    "import pylab as py\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from scripts.helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image directory\n",
    "input_dir= 'input_images/'\n",
    "input_img_names = os.listdir(input_dir)\n",
    "input_img_names = [items for items in input_img_names if items[-4:]=='.png' or items[-4:]=='.jpg']\n",
    "if len(input_img_names) == 0:\n",
    "    print('Please put the input images in input_images/ directory!')\n",
    "    \n",
    "for idx, image_name in enumerate(input_img_names):\n",
    "    img = Image.open('input_images/'+image_name)\n",
    "    r_width = 800\n",
    "    r_height = 320\n",
    "    r_img = transforms.Resize((r_height, r_width))(img)\n",
    "    r_img.save('transformed_images/'+image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocessing_fn, CLASSES = load_pretrained_model()\n",
    "DEVICE = ('cuda:4' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('saved_models/Trained_model_SM.pth').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(\n",
    "    images_dir = 'transformed_images/',\n",
    "    masks_dir=None,\n",
    "    augmentation = get_validation_augmentation(),\n",
    "    preprocessing = get_preprocessing_unlabeled(preprocessing_fn),\n",
    "    classes = CLASSES,\n",
    ")\n",
    "\n",
    "test_dataset_viz = Dataset(\n",
    "    images_dir = 'transformed_images/',\n",
    "    masks_dir=None,\n",
    "    classes = CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_img_names = os.listdir('transformed_images/')\n",
    "output_img_names = [items for items in input_img_names if items[-4:]=='.png' or items[-4:]=='.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the legends\n",
    "legend_img = Image.open('Legends.png')\n",
    "w_legend, h_legend = legend_img.size\n",
    "ar = w_legend/h_legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_no, image_name in enumerate(output_img_names):\n",
    "    image_viz, mask_viz = test_dataset_viz[test_no]\n",
    "    image, mask = test_dataset[test_no]\n",
    "    img_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    pred_mask = model.predict(img_tensor)\n",
    "    pred_mask = pred_mask.squeeze().cpu().numpy().round()\n",
    "    input_img_viz = Image.fromarray(image_viz)\n",
    "    new_h = input_img_viz.size[1]\n",
    "    legend = legend_img.resize((int(new_h*ar), new_h), Image.ANTIALIAS)\n",
    "    np.save('segmented_outputs/'+image_name[:-4]+'.npy', pred_mask)\n",
    "    get_color_img(pred_mask, normal=False).save('segmented_images/'+image_name)\n",
    "    get_concat_h(\n",
    "        get_concat_h(\n",
    "            Image.fromarray(image_viz),\n",
    "            get_color_img(pred_mask, normal=False)\n",
    "        ), \n",
    "        legend\n",
    "    ).save('joint_images/'+image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
